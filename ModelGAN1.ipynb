{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelGAN1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+sKGaUmrHTkx3mGd7YpVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivendr7/ml/blob/GANs/ModelGAN1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdAT8A1hED4P"
      },
      "source": [
        "Hi, in this lesson you will discover how to implement a simple discriminator and generator model using the Keras deep learning library.\r\n",
        "\r\n",
        "We will assume the images in our domain are 28x28 pixels in size and color, meaning they have three color channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzL_93j07jbB"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense\r\n",
        "from tensorflow.keras.layers import Flatten, BatchNormalization\r\n",
        "from tensorflow.keras.layers import Activation, ZeroPadding2D\r\n",
        "from tensorflow.keras.layers import LeakyReLU\r\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D, Conv2DTranspose\r\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\r\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB_v5fl8EFcX"
      },
      "source": [
        "Discriminator Model\r\n",
        "The discriminator model accepts an image with the with size 28x28x3 pixels and must classify it as real (1) or fake (0) via the sigmoid activation function.\r\n",
        "\r\n",
        "Our model has two convolutional layers with 64 filters each and uses same padding. Each convolutional layer will downsample the input using a 2x2 stride, which is a best practice for GANs, instead of using a pooling layer.\r\n",
        "\r\n",
        "Also following best practice, the convolutional layers are followed by a LeakyReLU activation with a slope of 0.2 and a batch normalization layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtJFIz0pEJCA"
      },
      "source": [
        "def build_discriminator():\r\n",
        "  model= Sequential()\r\n",
        "\r\n",
        "  #downsample to 14x14\r\n",
        "  model.add(Conv2D(64,(3,3), strides=(2,2), padding='same', input_shape=(28,28,3)))\r\n",
        "  model.add(LeakyReLU(alpha=0.2))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "  \r\n",
        "  #downsample to 7x7\r\n",
        "  model.add(Conv2D(64,(3,3), strides=(2,2), padding='same'))\r\n",
        "  model.add(LeakyReLU(alpha=0.2))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "  \r\n",
        "  #classify\r\n",
        "  model.add(Flatten())\r\n",
        "  model.add(Dense(1, activation='sigmoid'))\r\n",
        "  model.summary()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gey6_KQGFu3S",
        "outputId": "f951ab6b-b22f-4ff9-ba73-056359749a7a"
      },
      "source": [
        "build_discriminator()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 14, 14, 64)        1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 3137      \n",
            "=================================================================\n",
            "Total params: 42,369\n",
            "Trainable params: 42,113\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uKArNBqGGxd"
      },
      "source": [
        "Generator Model\r\n",
        "The generator model takes a 100-dimensional point in the latent space as input and generates a 28x28x3.\r\n",
        "\r\n",
        "The point in latent space is a vector of Gaussian random numbers. This is projected using a Dense layer to the basis of 64 tiny 7x7 images. The small images are then upsampled twice using two transpose convolutional layers with a 2x2 stride and followed by a LeakyReLU and BatchNormalization layers, which are a best practice for GANs.\r\n",
        "\r\n",
        "The output is a three channel image with pixel values in the range [-1,1] via the Tanh activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLpjAQo7GIYq"
      },
      "source": [
        "def build_generator():\r\n",
        "  model= Sequential()\r\n",
        "\r\n",
        "  #formation for 7x7 image\r\n",
        "  n_nodes= 64*7*7\r\n",
        "  model.add(Dense(n_nodes, input_dim=100))\r\n",
        "  model.add(LeakyReLU(alpha=0.2))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "  model.add(Reshape((7,7,64)))\r\n",
        "\r\n",
        "  #upsampling to 14x14\r\n",
        "  model.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same'))\r\n",
        "  model.add(LeakyReLU(alpha=0.2))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "\r\n",
        "  #upsampling to 28x28\r\n",
        "  model.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same'))\r\n",
        "  model.add(LeakyReLU(alpha=0.2))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "  model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\r\n",
        "\r\n",
        "  model.summary()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQxIW2JMHx5g",
        "outputId": "1b31a56e-2734-4b39-dd4f-199e62fc9690"
      },
      "source": [
        "build_generator()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 3136)              316736    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 3136)              12544     \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 3)         1731      \n",
            "=================================================================\n",
            "Total params: 405,379\n",
            "Trainable params: 398,851\n",
            "Non-trainable params: 6,528\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}