{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResnetsCIFARpart1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM2ZNtwNOt6//NSq19ZJWem",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivendr7/ml/blob/main/ResnetsCIFARpart1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj4PGjEbzRKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72197e6-bb70-4912-f1e2-77ae2c37d14e"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "import tensorflow.keras\r\n",
        "from tensorflow.keras.layers import  Dense, Conv2D\r\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\r\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\r\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.regularizers import l2\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.datasets import cifar10\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "(x_train, y_train), (x_test, y_test)= cifar10.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daavHQwn1Uno"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from six.moves import cPickle\r\n",
        "\r\n",
        "R=10\r\n",
        "\r\n",
        "x=x_train.astype('uint8')\r\n",
        "\r\n",
        "fig, axes= plt.subplots(R, R, figsize=(10, 10))\r\n",
        "\r\n",
        "for i in range(R):\r\n",
        "  for j in range(R):\r\n",
        "    k=np.random.choice(range(len(x)))\r\n",
        "    axes[i][j].set_axis_off()\r\n",
        "    axes[i][j].imshow(x[k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "QPrIPjJb2e0M",
        "outputId": "bc381282-b645-45ac-9a04-dfa2be1d4686"
      },
      "source": [
        "plt.imshow(x[1], cmap='gray', interpolation='nearest')\r\n",
        "x.shape, x[:1].shape, x[1].shape, x[2:3][0].shape,y_train[1]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3),\n",
              " (1, 32, 32, 3),\n",
              " (32, 32, 3),\n",
              " (32, 32, 3),\n",
              " array([9], dtype=uint8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTgQLKn85ATt"
      },
      "source": [
        "#learning rate decay schedule\r\n",
        "def lr_schedule(epoch):\r\n",
        "  lr=1e-3\r\n",
        "  if epoch>180:\r\n",
        "    lr*=0.5e-3\r\n",
        "  elif epoch>160:\r\n",
        "    lr*=1e-3\r\n",
        "  elif epoch>120:\r\n",
        "    lr*=1e-2\r\n",
        "  elif epoch>80:\r\n",
        "    lr*=1e-1\r\n",
        "  print('changed learning rate:',lr)\r\n",
        "  return lr"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3c8h6S36fEm"
      },
      "source": [
        "def resnet_layer(inputs,\r\n",
        "                 num_filters=16,\r\n",
        "                 kernel_size=3,\r\n",
        "                 strides=1,\r\n",
        "                 activation='relu',\r\n",
        "                 batch_normalization=True,\r\n",
        "                 conv_first=True):\r\n",
        "  \"\"\"2D Convolution-Batch Normalization-Activation stack builder\r\n",
        "\r\n",
        "    # Arguments\r\n",
        "        inputs (tensor): input tensor from input image or previous layer\r\n",
        "        num_filters (int): Conv2D number of filters\r\n",
        "        kernel_size (int): Conv2D square kernel dimensions\r\n",
        "        strides (int): Conv2D square stride dimensions\r\n",
        "        activation (string): activation name\r\n",
        "        batch_normalization (bool): whether to include batch normalization\r\n",
        "        conv_first (bool): conv-bn-activation (True) or\r\n",
        "            bn-activation-conv (False)\r\n",
        "\r\n",
        "    # Returns\r\n",
        "        x (tensor): tensor as input to the next layer\r\n",
        "    \"\"\"\r\n",
        "  conv=Conv2D(num_filters,\r\n",
        "                kernel_size=kernel_size,\r\n",
        "                strides=strides,\r\n",
        "                padding='same',\r\n",
        "                kernel_initializer='he_normal',\r\n",
        "                kernel_regularizer=l2(1e-4))\r\n",
        "  x=inputs\r\n",
        "  if conv_first:\r\n",
        "    x=conv(x)\r\n",
        "    if batch_normalization:\r\n",
        "      x=BatchNormalization()(x)\r\n",
        "    if activation is not None:\r\n",
        "      x=Activation(activation)(x)\r\n",
        "  else:\r\n",
        "    if batch_normalization:\r\n",
        "      x=BatchNormalization()(x)\r\n",
        "    if activation is not None:\r\n",
        "      x=Activation(activation)(x)\r\n",
        "    x=conv(x)\r\n",
        "  \r\n",
        "  return x\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1ekGQrmcdiG",
        "outputId": "8fe48c46-8ed7-47f8-f861-4cfe9fd9bd31"
      },
      "source": [
        "from tensorflow.keras.layers import Add\r\n",
        "\r\n",
        "inputs=Input(shape= x_train.shape[1:])\r\n",
        "\r\n",
        "outputs=resnet_layer(inputs=inputs)\r\n",
        "#shorting=Add()([inputs,outputs])\r\n",
        "modelResnetLayer=Model(inputs=inputs, outputs=outputs)\r\n",
        "modelResnetLayer.compile()\r\n",
        "modelResnetLayer.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 16)        448       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 16)        0         \n",
            "=================================================================\n",
            "Total params: 512\n",
            "Trainable params: 480\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGO6X6Sbau5T",
        "outputId": "5146a3ad-efdc-499a-ca50-fe023cbf0ba9"
      },
      "source": [
        "# (kernel_Width*kernel_height*layers_in_prev+1(bias))*layers_in_current\r\n",
        "# batch normalization params= 4*no. of layers in current [in mode 1]\r\n",
        "(5*5*3+1)*32"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2432"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogYkFsXxKvfN",
        "outputId": "55e485f2-04e6-47fa-fd49-b4b86f2ad2e7"
      },
      "source": [
        "from tensorflow.keras.layers import Add\r\n",
        "\r\n",
        "inputs=Input(shape= x_train.shape[1:])\r\n",
        "#done with padding valid\r\n",
        "outputs=resnet_layer(inputs=inputs,num_filters=32,kernel_size=5)\r\n",
        "#shorting=Add()([inputs,outputs])\r\n",
        "modelResnetLayer=Model(inputs=inputs, outputs=outputs)\r\n",
        "modelResnetLayer.compile()\r\n",
        "modelResnetLayer.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 32)        2432      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 28, 28, 32)        0         \n",
            "=================================================================\n",
            "Total params: 2,560\n",
            "Trainable params: 2,496\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKjjKB5HgeCD",
        "outputId": "1ba7cb41-ade7-4b7f-ebbe-f3a2f0ad5c5c"
      },
      "source": [
        "from tensorflow.keras.layers import MaxPooling2D\r\n",
        "inputs=Input(shape= x_train.shape[1:])\r\n",
        "\r\n",
        "outputs=resnet_layer(inputs=inputs)\r\n",
        "#outputs=MaxPooling2D(pool_size=8)(outputs)\r\n",
        "outputs=Flatten()(outputs)\r\n",
        "modelResnetLayer=Model(inputs=inputs, outputs=outputs)\r\n",
        "modelResnetLayer.compile()\r\n",
        "modelResnetLayer.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 16)        448       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "=================================================================\n",
            "Total params: 512\n",
            "Trainable params: 480\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hKs2pquuZL_"
      },
      "source": [
        "ResNet V1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWo7c_MeubGO"
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\r\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\r\n",
        "\r\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\r\n",
        "    Last ReLU is after the shortcut connection.\r\n",
        "    At the beginning of each stage, the feature \r\n",
        "    map size is halved (downsampled)\r\n",
        "    by a convolutional layer with strides=2, while the number of \r\n",
        "    filters is\r\n",
        "    doubled. Within each stage, the layers have the same number \r\n",
        "    filters and the same number of filters.\r\n",
        "    Features maps sizes:\r\n",
        "    stage 0: 32x32, 16\r\n",
        "    stage 1: 16x16, 32\r\n",
        "    stage 2:  8x8,  64\r\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\r\n",
        "    ResNet20 0.27M\r\n",
        "    ResNet32 0.46M\r\n",
        "    ResNet44 0.66M\r\n",
        "    ResNet56 0.85M\r\n",
        "    ResNet110 1.7M\r\n",
        "\r\n",
        "    # Arguments\r\n",
        "        input_shape (tensor): shape of input image tensor\r\n",
        "        depth (int): number of core convolutional layers\r\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\r\n",
        "\r\n",
        "    # Returns\r\n",
        "        model (Model): Keras model instance\r\n",
        "    \"\"\"\r\n",
        "    if (depth-2)%6 !=0:\r\n",
        "      raise ValueError('depth should be 6n+2')\r\n",
        "\r\n",
        "    #model definition\r\n",
        "    num_filters=16\r\n",
        "    num_res_blocks=int((depth-2)/6)\r\n",
        "\r\n",
        "    inputs=Input(shape= input_shape)\r\n",
        "    x= resnet_layer(inputs= inputs)\r\n",
        "    #Intantiate the stack of residual units\r\n",
        "\r\n",
        "    for stack in range(3):\r\n",
        "      for res_block in range(num_res_blocks):\r\n",
        "        # first layer but not first stack\r\n",
        "        strides=2 if stack>0 and res_block==0 else 1\r\n",
        "\r\n",
        "        y=resnet_layer(inputs=x, num_filters=num_filters, strides=strides)\r\n",
        "        y=resnet_layer(inputs=y, num_filters=num_filters, activation=None)\r\n",
        "\r\n",
        "        # first layer but not first stack\r\n",
        "        if stack>0 and res_block==0:\r\n",
        "          # linear projection residual shortcut connection to match\r\n",
        "          # changed dims\r\n",
        "\r\n",
        "          x= resnet_layer(inputs=x, \r\n",
        "                          num_filters= num_filters,\r\n",
        "                          kernel_size=1,\r\n",
        "                          strides=strides,\r\n",
        "                          activation=None,\r\n",
        "                          batch_normalization=False)\r\n",
        "          x= tensorflow.keras.layers.add([x,y])\r\n",
        "          x= Activation('relu')(x)\r\n",
        "\r\n",
        "        num_filters *=2\r\n",
        "      \r\n",
        "    x=AveragePooling2D(pool_size=8)(x)\r\n",
        "    y=Flatten()(x)\r\n",
        "\r\n",
        "    outputs= Dense(num_classes,\r\n",
        "                     activation='softmax',\r\n",
        "                     kernel_initializer='he_normal')(y)\r\n",
        "\r\n",
        "    model= Model(inputs= inputs, outputs=outputs)\r\n",
        "    return model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfFzpzBJ52ys",
        "outputId": "9a3e1945-aa49-4f91-d151-ac557613d867"
      },
      "source": [
        "x_train.shape[1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AWyUsP7yD52",
        "outputId": "7b7a162a-d73a-40a6-9d0f-fbdd4dee9eb5"
      },
      "source": [
        "x_train = x_train.astype('float32') /255\r\n",
        "x_test = x_test.astype('float32') / 255\r\n",
        "\r\n",
        "y_train_label=tensorflow.keras.utils.to_categorical(y_train, 10)\r\n",
        "y_test_label=tensorflow.keras.utils.to_categorical(y_test, 10)\r\n",
        "\r\n",
        "model=resnet_v1(input_shape=x_train.shape[1:], depth=(x_train.shape[3]*6 +2))\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\r\n",
        "              metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "changed learning rate: 0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 128)  18560       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 128)  147584      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 128)  2176        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 16, 16, 128)  0           conv2d_9[0][0]                   \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 1024)   1180672     activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 1024)   4096        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 8, 8, 1024)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 1024)   9438208     activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 1024)   132096      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 1024)   4096        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 8, 8, 1024)   0           conv2d_16[0][0]                  \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 1024)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 1024)   0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1024)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           10250       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 10,939,274\n",
            "Trainable params: 10,934,634\n",
            "Non-trainable params: 4,640\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njyOsyAmH14r",
        "outputId": "c5881696-d675-411a-bc04-ef93643e35d3"
      },
      "source": [
        "x_train.shape,y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7WsWvFXYfPp",
        "outputId": "30a92d2d-6156-47f0-d36d-55d1e59af70c"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "x = tf.constant([[1., 2., 3.],\r\n",
        "                 [4., 5., 6.]])\r\n",
        "print(x.shape,x)\r\n",
        "x = tf.reshape(x, [1, 2, 3, 1])  # give a shape accepted by tf.nn.max_pool\r\n",
        "print(x.shape,x)\r\n",
        "valid_pad = tf.nn.max_pool(x, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\r\n",
        "same_pad = tf.nn.max_pool(x, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\r\n",
        "\r\n",
        "valid_pad.get_shape() == [1, 1, 1, 1],   same_pad.get_shape() == [1, 1, 2, 1]  # valid_pad is [5.] # same_pad is  [5., 6.]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3) tf.Tensor(\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
            "(1, 2, 3, 1) tf.Tensor(\n",
            "[[[[1.]\n",
            "   [2.]\n",
            "   [3.]]\n",
            "\n",
            "  [[4.]\n",
            "   [5.]\n",
            "   [6.]]]], shape=(1, 2, 3, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}